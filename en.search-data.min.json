[{"id":0,"href":"/medusa-docs/","title":"Welcome","parent":"","content":"The IPSY Docs is a collection of (primarily technical) information — presented in a way that is concise(-ish), opinionated, and directly relevant for those working in our mighty, mighty institute.\nCecile documentation If you are looking for documentation about the new Cecile cluster you can find a beta version here:\n https://ipsy-md.github.io/docs/ Once this is finished it will replace the current IPSY docs.\n  And now, an obligatory XKCD comic:\n "},{"id":1,"href":"/medusa-docs/how_to_ask/","title":"How to Ask for Help","parent":"Welcome","content":" \u0026quot;Computers are like Old Testament gods; lots of rules, and no mercy.\u0026quot;\n— Joseph Campbell Before you ask someone for help, be sure that you have done the following:\nIf there's an error message: read it closely. Though sometimes unclear, all contain information that can help you to understand what's happening. Think about the task you're trying to perform, and as many of the behind-the-scenes steps involved as you can. Consider how the error fits into that stack. Which part of the system is throwing the error: your script, another command, the language, the file system, the network? If the error message isn't immediately helpful, search for it using a search engine. Read the documentation and/or man page. Perhaps what you think you're doing is not actually what the command is doing.  If you have considered the above, and both your insight and search engine skills are failing you, then it's likely time to ask someone else for help.\nWhen asking someone for help, be sure to provide them with the following information:\nclearly describe what you're trying to do provide the error message (if any) explain what you've already done to fix/understand this problem  A good rule is that the amount of effort you put into understanding/solving a problem is the maximum effort that the other person will invest. To apply this rule to a common situation: if your description is that \u0026quot;it doesn't work\u0026quot;, you should fully expect no response — as their response-effort precisely matches the effort you've invested into explaining your problem.\nWhen you find a solution to your problem, make sure that you are engaged with it — and understand it. The goal is not to just fix the immediate issue, but rather to build a body of knowledge and develop the broader skill of troubleshooting. Computers should be tools which empower you — rather than something inflicted upon you.\n"},{"id":2,"href":"/medusa-docs/medusa/","title":"Medusa","parent":"Welcome","content":"Medusa [1] is a small computational cluster used for neuroscience research by a hardy cohort of scientists at the Institute of Psychology II at the Otto-von-Guericke University of Magdeburg.\nMedusa is tailored to the analysis needs of psychology researchers — running Debian Linux with additional research software provided by NeuroDebian\nWhen you first use Medusa, you will use one machine: the head node. However, Medusa is a collection of servers, with many dedicated computational nodes. In order to use Medusa to its full potential, you will need to become familiar with our job scheduler, Condor.\n [1]Medusa, the monster from Greek mythology, had living snakes in place of her hair. The head node of the cluster is called \u0026quot;medusa\u0026quot; and each compute node is a \u0026quot;snake\u0026quot; (e.g. snake1, snake2, etc).   "},{"id":3,"href":"/medusa-docs/medusa/code_of_conduct/","title":"Code of Conduct","parent":"Medusa","content":" Sharing is caring. —Wise Person Medusa is a shared resource, and therefore should be used with awareness and empathy for the work of others. Specific points to pay attention to are:\nUse Condor for analysis All computational jobs are to be submitted to the HTCondor queue. The head node is meant for interactive use and quick computations, otherwise it negatively affects other people's work. Anything bigger should be submitted as an HTCondor Job, either as an interactive job or as a non-interactive job. HTCondor Job descriptions should be accurate, and users should make an honest intellectual effort to adapt their jobs to the mythical \u0026quot;ideal job\u0026quot;. Be mindful of your storage space Treat storage space as if it's a finite resource (pro-tip: it is). Take the time to regularly remove obsolete data and temporary files. Temporary/easily-regeneratable data should be stored in a scratch/ directory. More information is available in the Data Documentation. Report anything strange/faulty If you notice something broken (or even just strange) while working on the cluster, take the time to report it to Alex or Nico. If something isn't right, it likely affects others too.  "},{"id":4,"href":"/medusa-docs/medusa/access/","title":"Accessing","parent":"Medusa","content":"Command Line The easiest and most reliable way of connecting to Medusa is via SSH.\nConnecting is as simple as running the following in your terminal:\nssh username\u0026#64;medusa.ovgu.de  NOTE: Users with unstable internet connections will likely find tmux to be a helpful tool.\n VPN You need a VPN connection to be able to log in to medusa. A description how to configure a VPN client can be found on the OVGU URZ page\n Graphical There are multiple methods of connecting to Medusa graphically.\nX Forwarding Graphical programs run on the remote server can be displayed locally using SSH's X Forwarding. Do note that X Forwarding is very sensitive to latency, so it is only practical to use when on the OvGU campus.\nssh -X username\u0026#64;medusa.ovgu.de   Sixel Sixel is mostly a toy right now. But it is quite convenient in the few situations where there is support (image and NIfTI previews). VNC VNC is for users who prefer a more familiar desktop experience or need to use graphical programs while off-campus. VNC is a multi-step process and not as easy as straight SSH.\nFirst, SSH into Medusa (explained above). Then setup your VNC password. You only need to do this once. The password is stored unencrypted in a text file, so do not use a valuable password (such as for Medusa, email, etc).\nme\u0026#64;medusa:~$ vncpasswd Password: Verify:  Next, start the VNC server.\nme\u0026#64;medusa:~$ vncserver New 'medusa:9 (me)' desktop is medusa:9 Starting applications specified in /home/me/.vnc/xstartup Log file is /home/me/.vnc/medusa:9.log  Note the number 9 in medusa:9. Yours will likely be different. Take note of your number, as it references your VNC session and will be used later.\nThe VNC server runs until it is terminated by you (or a reboot of Medusa). If you close your client/disconnect, it will continue to run. If you \u0026quot;log out\u0026quot; in the session, it will terminate the server.\nLinux Open a terminal and run the following:\nvncviewer -via medusa.ovgu.de :9  Note the :9. Make sure that this is your number from above. This command will first ask that you authenticate to Medusa, and then it will ask for the VNC password you set before.\n macOS macOS has a VNC client built-in, but it isn't SSH aware. So a SSH tunnel needs to be setup first.\nssh -f -L 5909:127.0.0.1:5909 username\u0026#64;medusa.ovgu.de sleep 60  Then you can use VNC.\nopen vnc://127.0.0.1:5909  Note the number \u0026quot;5909\u0026quot; in both commands. It should be 5900 + the number noted above. Make sure that it is your number.\nTODO: write a simple shell script that can be curl-ed into the user's path.\n Windows Windows lacks a built-in VNC viewer, so you will need to download and install one of your choice, here VNC viewer is used. To be able to establish a ssh tunnel PuTTY is used in addition.\nConnect to medusa and start the VNC Server (after setting up your password) to get your session number. Open putty and specify Host Name as your medusa login (name\u0026#64;medusa.ovgu.de) and Port 22 On the right hand side, click on the + next to SSH and then click Tunnels. Type 59(session number) for Source port (e.g. if your session number is 11 type 5911). Type localhost:5900 + your unique session number (here 11) as Destination then click Add. (e.g. localhost:5911) Go back to Session. If you don't want to repeat this steps each time you connect to medusa, save this session. Load and open the session to connect to medusa. Open a VNC Viewer, type localhost:59(session number) and connect. You will be required to enter your VNC password. Afterwards you will have access to the GUI.  Note the port number: \u0026quot;5911\u0026quot;. It should be 5900 + the number we noted above. Make sure that it is your number.\nPutty:\nVNC Viewer:\n    After successfully establishing a VNC connection the desktop will look like this:\nHelpful Commands\nHow to show the list of started VNC servers:\nvncserver -list  How to kill the process from too many started vnc server (11 is the session number):\nvncserver -kill :11   "},{"id":5,"href":"/medusa-docs/medusa/htcondor/","title":"HTCondor","parent":"Medusa","content":"This document focuses on how HTCondor is configured and intended to be used on our cluster. To learn about Condor and how to use it, you should read the Tools \u0026gt; HTCondor page.\nHTCondor jobs come in two versions: interactive and non-interactive. Whenever possible, a non-interactive job should be used for computations.\nTODO: This page needs some love.\nThe \u0026quot;Ideal\u0026quot; Job The \u0026quot;ideal\u0026quot; job is [1 CPU × 4 GiB] and runs for 1-3 hours. Of course, not every analysis/step can be broken down into sub-jobs that match this ideal. But experience has shown that, with a little effort, the majority of analysis at IPSY can.\nSmaller jobs are good: simply, they are more granular and thus better fit (Tetris style) into the available compute resources.\nShorter jobs are also preferred; duration directly affects the turnover of jobs and how frequently compute resources become available. If 10,000x 1 hour jobs are submitted, after awhile, a job will be finishing every minute or so (due to normal variations across the cluster).\nMaintaining liquidity (aka job turnover) is critical for user priority to remain relevant (as discussed in the section Prioritization of Jobs) and ensure the fair-distribution-of and timely-access-to compute resources — rather than merely rewarding those who submit jobs first.\n10,000 jobs lasting 1 hour each is far better than 1,000 jobs lasting 10 hours each.\n Interactive Jobs Any task which takes more than a few minutes or uses a lot of CPU/RAM should not be run from the head node, but as an interactive job. This applies especially to working with datalad, as the underlying git annex calls can be CPU-intensive. To run an interactive job, use the following job submit file.\n Prioritization of Jobs Condor on Medusa is configured to assess user priority only when jobs are starting. The more compute resources consumed by the user, the more their priority is punished (increased). This \u0026quot;punishment\u0026quot; decays back to normal over the course of a day or two.\nIn practice, it works like this:\nJulie submits 30,000 jobs, each ~1 hour long A day later, Jimbo submits 10 jobs Jimbo's jobs wait in the queue As some of Julie's jobs finish, resources are freed up Both Julie's and Jimbo's jobs compete for the free resources. Jimbo's win because his priority is low (good) and hers is very high (bad).  There is also the Priority Factor. Users who are not members of IPSY have a modifier that punishes them even more. This way, in most cases, the jobs of IPSY members will be preferred over those of non-IPSY users.\nYou can check you usage, priority, and priority factor using condor_userprio --allusers.\n Slots Medusa is configured to allow a diversity of different job sizes, while protecting against large jobs swamping the entire cluster — and also encouraging users to break their analysis into smaller steps.\nThe slots on Medusa are:\n16x 1 cpu, 4 GiB ( 4.0 GiB/cpu) 8x 1 cpu, 5 GiB ( 5.0 GiB/cpu) 4x 10 cpu, 85 GiB ( 8.5 GiB/cpu) 1x 48 cpu, 190 GiB ( 3.9 GiB/cpu) 1x 8 cpu, 62 GiB ( 7.7 GiB/cpu)  All slots larger than 1 CPU are partitionable — and thus can be broken into many smaller slots. To illustrate: there are only 24x 1 CPU slots. But if 500x [1 CPU × 4 GiB] jobs are submitted, all of the larger slots are broken up into matching [1 CPU × 4 GiB] slots — resulting in a total of 231 jobs.\nThe reader may have noticed that there are 124 CPUs, and yet only 123 jobs would be scheduled. This is because the [48 CPU × 190 GiB] slot (which has a RAM/CPU ratio \u0026lt; 4 GiB) cannot provide 4 GiB to each CPU; thus, one CPU is left idle.\nThe loss of 1 CPU for [1 CPU × 4 GiB] jobs is negligible. However, as an exercise, the reader is encouraged to determine how much of the cluster would be left idle when submitting [1 CPU × 5 GiB] jobs — and also [2 CPU × 20 GiB].\n Matlab By default, Matlab will use all available CPUs. The preferred way to control Matlab is to use the -singleCompthread option. There is also a maxNumCompThreads() function, but was deprecated but now seems to be back from the dead. Any feedback on the efficacy of these function in recent Matlab released (2019a and newer) is most appreciated.\nNOTE: With the increase in the number of available campus toolbox licenses, it is no longer necessary to restrict Matlab jobs to specific compute nodes.\nTODO: Discuss Matlab Compiler\n fMRIPrep By default, fMRIPrep will use all available CPUs and all the RAM it can get. Use the --nthreads and --mem-mb to limit its usage to the requested resources.\n Intel vs AMD Our cluster's Intel nodes have the fastest single thread performance. If you have very few, single CPU jobs and need them to execute as fast as possible, then restricting your jobs to the nodes with Intel CPUs can be beneficial.\nThe nodes are configured to advertise their CPU vendor, so it is easy to constrain according to CPU type. Add the following to your .submit file.\nRequirements = CPUVendor == \u0026quot;INTEL\u0026quot;  Or, to prefer Intel CPUs but not require them\nRank = CPUVendor == \u0026quot;INTEL\u0026quot;   "},{"id":6,"href":"/medusa-docs/medusa/data/","title":"Data","parent":"Medusa","content":"Folder Hierarchy All data in the /home directory is available across the entire cluster.\n/home/\u0026lt;user_name\u0026gt; This directory is for all of your personal files. /home/data/\u0026lt;project_name\u0026gt; This directory is for data shared across the group/project. /home/\u0026lt;user_name\u0026gt;/scratch or /home/data/\u0026lt;project_name\u0026gt;/scratch This directory is not backed-up and should be used to store interim results which can be easily regenerated. Storing data here helps relieve the burden on backups. /home/data/archive/\u0026lt;project_name\u0026gt; Read-only and heavily compressed (via cool transparent compression mojo), this directory stores data for projects which are completed.   DataLad When starting new projects, it is highly recommended to use DataLad to ease remote data acquisition and provenance tracking.\n Backups All data located under the /home directory are snapshot at 05:00 every day — except for any data located in the /home/\u0026lt;user_name\u0026gt;/scratch or /home/data/\u0026lt;project_name\u0026gt;/scratch folders. Snapshots are then transferred to a dedicated backup server.\nThe backup retention policy is:\ndaily backups executed daily at 05:00 kept for 2 weeks   weekly backups executed on Mondays at 05:10 kept for 6 weeks   monthly backups executed on the 1st of every month at 05:20 kept for 1 year    If you need to have data recovered from a backup, contact the system administration to help recover your data.\n To/From Medusa rsync This is the tool for efficient and reliable transfer.\nrsync -rltoDvh --progress dir_here/ user\u0026#64;medusa.ovgu.de:~/dir_there   WinSCP or Cyberduck If you prefer using a GUI, WinSCP (Windows) and Cyberduck (macOS and Windows) are decent SFTP clients.\nTo connect to Medusa: install and launch your client. Enter the information for host (sftp://medusa.ovgu.de), user, and password. Click connect. Once connected, you can drag-and-drop files to transfer.\n  TODO: explain SFTP/SSHFS on a per OS basis. Nautilus integration, sshfs on Linux and macOS, and SSHFS-Win on Windows.\n "},{"id":7,"href":"/medusa-docs/medusa/software/","title":"Software","parent":"Medusa","content":"A wide variety of software is installed across the cluster (AFNI, FSL, FreeSurfer, Octave, Python, R, Matlab, etc). The majority of software is configured to work out-of-the-box, but some software requires additional setup by each user before they can be used.\nSoftware Stack To make all software needed by the users available in a reproducable way Medusa uses software stacks.\nFurther information can be found via Software stack\n AFNI AFNI ships with commands which are named the same as commands from other packages, so to enable AFNI, run the following:\nsource /etc/afni/afni.sh  This needs to be run each time you start a new session on the cluster. If you prefer that it be run automatically, you can add it to your .zshrc file.\nNOTE: The following commands are known to have conflicts: whirlgif (FSL, wims), gifti_test (FreeSurfer), gifti_tool (FreeSurfer), nifti1_test (Niftilib), nifti_stats (Niftilib), nifti_tool (Niftilib), and whereami (whereami).\n ANTs ANTs' configuration is setup using something called \u0026quot;environmental modules.\u0026quot;\nFirst, \u0026quot;modules\u0026quot; must be loaded:\nsource /etc/profile.d/modules.sh  Then, to load version 2.2.0, run the following:\nmodule load ants/2.2.0  Now you can use ANTs.\nThe process needs to be performed each time you start a new session on the cluster. If you'd rather it be done automatically, add the following lines to your .zshrc file.\nsource /etc/profile.d/modules.sh module load ants/2.2.0  NOTE: There are no known namespace conflicts with other commands, so it should be safe to add the above lines to your .zshrc.\n FreeSurfer FreeSurfer's configuration is setup using something called \u0026quot;environmental modules.\u0026quot;\nFirst, \u0026quot;modules\u0026quot; must be loaded:\nsource /etc/profile.d/modules.sh  Then, you can query which versions of FreeSurfer are available:\nmodule avail freesurfer  Then, to load version 6.0, run the following:\nmodule load freesurfer/6.0  Now you can use FreeSurfer.\nThe process needs to be performed each time you start a new session on the cluster. If you'd rather it be done automatically, add the following lines to your .zshrc file.\nsource /etc/profile.d/modules.sh module load freesurfer/6.0  NOTE: The following commands are known to have conflicts: gifti_test (AFNI), gifti_tool (AFNI), and dsh (dsh).\n FSL FSL ships with commands which are named the same as commands from other packages, so all FSL commands are prepended with fsl5.0-.\nTo configure FSL with defaults and remove the fsl5.0- prefix, run the following:\nsource /etc/fsl/fsl.sh  This needs to be run each time you start a new session on the cluster. If you prefer that it be run automatically, you can add it to your .zshrc file.\nNOTE: The following commands are known to have conflicts: whirlgif (AFNI) and cluster (graphviz).\n MATLAB Multiple versions of Matlab are installed on the cluster. Because of this, there is no single matlab command. Instead, each version is suffixed with its version number (for example matlab94).\nThis suffixing is also applied to mex, mbuild, lmutil, and mcc.\nYou can check the current license usage by running:\nlmutil96 lmstat -a -c 1984\u0026#64;liclux.urz.uni-magdeburg.de   Python Python 2.7 and 3.5 are installed on the cluster — along with a wide variety of modules that are available to import.\nIf you need a python module that is not yet installed and think it is of interest and utility to other cluster users, just ask Alex to deploy it on the cluster. Alternatively, you can install it in a virtualenv.\n R R 3.3 is installed on the cluster — along with a wide variety of packages from CRAN that are available via the library() command.\nIf you need an R package that is not yet installed (and there is a Debian package for it), just ask Alex to deploy it on the cluster. Alternatively, you can install it from CRAN.\n "},{"id":8,"href":"/medusa-docs/medusa/software/software_stacks/","title":"Software stacks","parent":"Software","content":"The software stacks are shared for the whole cluster and are generated using the Spack package manager\nTypes of available software stacks Currently there are two types of stacks available.\ncurrent  stable stack throughout the semester new stack every semester (build from stratch) \u0026ldquo;old\u0026rdquo; stacks still valid with current_\u0026lt;date\u0026gt; 3 ways to access (further details see Usage):  directly with spack commands via modules via environment    Paths:\n stack: /home/data/software/current environment: /home/data/software/current/ipsy_env  experimental  stack that will be updated regularly and on short notice user requests updating instead of building from scratch can lead to multiple versions of software (e.g. python ~gcc@11.0 vs python ~gcc@11.1) same access methods as in current are available, but due to multiple versions not unambiguous\n-\u0026gt; recommended method: use environment to load stack  Paths:\n stack: /home/data/software/experimental environment: /home/data/software/experimental/ipsy_env  Usage There are multiple ways to use the software stacks, depending on how much control you want over what packages are loaded (and in which way):\n ipsy env directly via spack via modules  load ipsy environment Instead of loading every package individually an evironment can be activated containing only the newest version of each package.\nThis is the recommended way for most users.\n$ . /home/data/software/current/ipsy-env/activate all packages inside of the environment are now loaded and can be used directly.\ne.g.: to start python:\n$ python To see what software is available run:\nmodule avail via modules For every installed package spack generates a module file in addition meaning that classic module commands can be used as well.\nAgain shell support has to be enabled\n$ . /home/data/software/current/env.sh to see what packages are installed run\n$ module avail to load a package\n$ module load python or if a specific version is needed, load the entry shown in module avail\n$ spacktivate -p  ``` 2. Adding all packages that one wants to use in the enviroment For example, all pre-installed R-packages ``` $ spack add r $ spack add r-rstan ``` One can verify the list of added packages with ``` $ spack find # returns the following: == In environment  == Root specs r r-rstan ``` 3. Concretize the environment. This step makes all the `add`ed packages actually available within the environment ``` $ spack concretize ``` Note: This command can the a while to run. 4. Create load-script for loading all packages We will use a script which spack generates for us: ``` $ spack env loads -r ``` Whenever you want to activate the environment and the installed packages, simply run the suggested command: ``` $ . /loads ``` for more infos on spack environments, see [the docs](https://spack.readthedocs.io/en/latest/environments.html) or the [tutorial](https://spack-tutorial.readthedocs.io/en/latest/tutorial_environments.html) -- "},{"id":9,"href":"/medusa-docs/medusa/data_center/","title":"Data Center","parent":"Medusa","content":"We have 5U in one of the racks in the G26 data center. It houses the backup server (Thunk).\n  PWR U# Name Inventory # Overview   \u0026nbsp; 4 JBOD (Thunk) (likely part of 264097,000) 9x 4TB drives / 12x bays  5  \u0026nbsp; 6 Thunk 261309,000 2x 6-core 2.4 GHz Xeon E5645 96 GiB RAM\n12x 4TB drives / 16x bays\n  7  8    Also in G26, the URZ provided us with 2x 42U racks. The left rack is where medusa is located and the right one is meant for the new cluster (currently under construction). The contents of the Medusa rack are (as of 2021.10.22):\n  PWR U# Name Inventory # Overview   \u0026nbsp; 1 Router 1019378 SG-8860  \u0026nbsp; 2 Mgmt. Switch \u0026nbsp; 24 Port HP ProCurve 1700-24  \u0026nbsp; 3 Cable Management \u0026nbsp; \u0026nbsp;  \u0026nbsp; 4 Data Switch \u0026nbsp; provided by URZ  \u0026nbsp; 5 Cable Management \u0026nbsp; \u0026nbsp;  \u0026nbsp; 6 Power Transfer Switch \u0026nbsp; provided by URZ  \u0026nbsp; 7 Mulder 260876,000 1x 4-core 3.2 GHz Xeon E3-1230 16 GiB RAM (turned off)  8  \u0026nbsp; 9 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 10 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 11 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 12 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 13 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 14 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 15 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 16 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 17 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 18 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 19 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 20 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 21 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 22 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 23 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 24 \u0026nbsp; \u0026nbsp; \u0026nbsp;  \u0026nbsp; 25 snake11 1019380,000 2x 10-core 2.3 GHz Xeon E5-2650v3 96 GiB DDR4 RAM (hardware defect)  26  \u0026nbsp; 27 snake10 267616,000 4x 8-core 2.8 GHz Opteron 6320 512 GiB RAM (hardware defect)  \u0026nbsp; 28 snake9 246831,000 1x 8-core 2.0 GHz Opteron 6128 64 GiB RAM  \u0026nbsp; 29 snake8 245075,000 1x 4-core 2.67 GHz i7 920 18 GiB RAM (hardware defect)  30  \u0026nbsp; 31 snake7 \u0026nbsp; 4x 16-core 2.4 GHz Opteron 6272 256 GiB RAM  \u0026nbsp; 32 snake5 \u0026amp; snake6 261309,000 (guessing) each snake:\n2x 6-core 2.4 GHz Xeon E5645 96 GiB RAM (snake5 hardware defect)\n  \u0026nbsp; 33 snake3 \u0026amp; snake4  \u0026nbsp; 34 snake1 \u0026amp; snake2  \u0026nbsp; 35 Medusa 265021,000 4x 8-core 2.8 GHz Opteron 6320 256 GiB RAM  36  \u0026nbsp; 37 Zing 1031333 13x 3.84TiB SanDisk Optimus 2 Max / 24x bays  38  \u0026nbsp; 39 JBOD (Zing) 265526,000 6x 4TB HDD / 12x bays  40  \u0026nbsp; 41 UPS \u0026nbsp; 3000 VA  42    "},{"id":10,"href":"/medusa-docs/medusa/hardware/","title":"Hardware","parent":"Medusa","content":"Summary As of July 2020, the cluster comprises 15 nodes with over 250 CPU cores and 2.25 TiB of RAM. Centralized storage features more than 40 TiB of high performance SSD and 11 TiB of HDD capacity, and is accessed by cluster nodes via 10Gb Ethernet.\n Head Node (Medusa) 4x 8-core 2.8 GHz Opteron 6320 256 GiB RAM (16x 16GiB DDR3 ECC reg) 1x 10Gb NIC  Purchased 2013.12. Supermicro's specs: A+ Server 2042G-TRF.\n Data Node (Zing) 1x 8-core 3.2 GHz Xeon E5-1660 v4 96 GiB RAM (6x 16GB DDR4 2133 ECC reg) 42 TiB SSD (~29.3 TiB usable) and ~26 TiB HDD (~10.5 TiB usable) storage 2x 10Gb bonded NICs  Purchased in 2016.12. Supermicro's specs: SuperChassis 216BE1C-R920LPB and Mainboard X10SRL-F\n Backup Node (Thunk) The only server in this list that is not hosted in G01. It is instead across campus in the G26 data center.\n2x 6-core 2.4 GHz Xeon E5645 96 GiB RAM (12x 8GB DDR3 ECC reg) 76.4 TiB HDD (52.1 TiB usable) storage 1x 1Gb NIC  Purchased 2011.12. Supermicro's specs: SuperChassis 836E16-R1200B and Mainboard X8DTH-iF\n snake1-6 2x 6-core 2.4 GHz Xeon E5645 96 GiB RAM (12x 8 GiB DDR3 ECC reg) 1x 1Gb NIC  Purchased 2011.12. Supermicro's specs: Twinserver 6016TT-TF\n snake7 4x 16-core 2.4 GHz Opteron 6272 256 GiB RAM (32x 8 GiB DDR3 ECC reg) 1x 1Gb NIC  Purchased 2012.06. Supermicro's specs: H8QG6+-F Motherboard\n snake8 1x 4-core 2.67 GHz i7 920 18 GiB RAM 1x 1Gb NIC  Purchased 2010.03; formerly amras. Supermicro's specs: RM21706 Chassis and X8STE Motherboard\n snake9 1x 8-core 2.0 GHz Opteron 6128 64 GiB RAM (8x 8GiB DDR3 ECC Reg) 1x 1Gb NIC  Purchased 2010 (estimated); formerly \u0026quot;just laying about\u0026quot; in Toemme's lab. Supermicro's specs: H8DGU-F Motherboard\n snake10 4x 8-core 2.8 GHz Opteron 6320 512 GiB RAM (32x 16GiB DDR3 ECC Reg) 1x 1Gb NIC  Purchased 2013.12. Supermicro's specs: A+ Server 1042G-TF\n snake11 2x 10-core 2.3 GHz Intel Xeon E5-2650v3 96 GiB RAM (6x 16GiB DDR4 ECC Reg) 1.2 TB NVMe mounted at /tmp 1x 10Gb NIC  Purchased 2015.12. Supermicro's specs: 825TQ-R740LPB Chassis and X10DRi-T Motherboard\n Mulder 1x 4-core 3.2 GHz Intel Xeon E3-1230 16 GiB RAM (4x 4GiB DDR3) 5.5 TB mounted at /media/data 2x 1Gb Nic (?)  TODO: Add Mulder's specs\n Networking An SG-8860 running OpenBSD acts as the router/firewall/etc for the cluster. All cluster traffic uses one 1Gb connection. All web services use a separate 1Gb connection. Internally, the data network is 10Gb (though not all hosts have 10Gb cards). Both the management and DMZ networks are physically separate.\n Power We have one zero-U 3-phase PDU (Raritan PX2-2730). It is connected to a red IEC_60309 power plug. For specifics on which machine is plugged into which PDU outlet, consult the rack diagram.\nAs we have limited battery capacity, only critical equipment is protected by the UPSs. Both UPSs are monitored by zing via NUT; the head node and zing poll this information; if the main UPS (Eaton) reaches low battery, both Medusa and Zing will shutdown immediately.\nAPC Smart-UPS SC 1000 age: ~2009 protects router and switches   Eaton 5PX 2200 age: 2012.12 protects Medusa and Zing     "},{"id":11,"href":"/medusa-docs/labs/","title":"Experimental Labs","parent":"Welcome","content":" "},{"id":12,"href":"/medusa-docs/tools/","title":"Tools","parent":"Welcome","content":" The greatest of compliments is using a tool in a way never anticipated by the inventor. "},{"id":13,"href":"/medusa-docs/labs/g23_r010_eeg/","title":"G23-R010: EEG","parent":"Experimental Labs","content":"This lab is operated by the Ullsperger Lab.\nFor questions, problems, or scheduling, contact Christina Becker.\nOverview The lab has two soundproof cabins with Faraday cages for EEG experiments. Each cabin has its own KVM matrix, which allows for nearly complete flexibility over which computer (EEG recorder, Eye Tracker, Presentation Machine, or researcher supplied Laptop) displays to any screen — and routes both audio and USB.\nThe KVM matrices are also interconnected, so one machine can display to both cabins.\nCabin 1 (left) EEG; speakers; eye tracking Cabin 2 (right) EEG; pain stimulation; Current Designs peripherals   Software The Presentation Computers run Windows 7 and have been configured in compliance with Brain Products' official guidelines. These machines should never, under any circumstances, be connected to the network.\nBoth machines run Matlab (2012b) and Presentation (multiple versions).\n EEG Brain Products is the EEG equipment vendor used in this laboratory.\nCabin 1 (left) 2x 32-channel BrainAmp MR Plus 1x 16-channel BrainAmp ExG MR   Cabin 2 (right) 2x 32-channel BrainAmp DC 1x 16-channel BrainAmp ExG MR    The additional Brain Products peripherals available are:\n2x StimTrak 2x Photodiode 1x Acoustical Stimulator Adapter 2x GSR (Galvanic Skin Response) sensor   Eye Tracker SR Research EyeLink 1000\nTODO: discuss camera speed, mount, etc\n Current Designs A Current Designs 932 unit is connected to the Presentation Computer of the right cabin. The following MR safe peripherals are available:\nTethyx Joystick Bimanual Grip Force   Pain Stimulation Two Digitimer current stimulators are available, the DS5 and DS7A. In practice, however, only the DS7A is used, as the DS5 is unable to provide enough current to be aversive enough for subjects.\nThe DS7A pulse can be triggered by software, but the intensity cannot be controlled by software. Thus, the initial calibration must be done manually.\n Speakers Avantone Passive MixCubes were selected because they have a well understood sonic profile (modeled after the well known Auratones) and an overall linear frequency response. They are also shielded, to prevent interference.\n KVM Matrix The Gefen EXT-DVIKVM-444DL KVM Matrix (datasheet; manual) is the key piece that makes it possible to use all the computers, screens, USB peripherals, and audio devices — in all the needed combinations. It is also a DVI amplifier, enabling reliable signal for the longer cable runs into the EEG cabins.\nEach matrix can connect to 4 computers (1x DVI; 1x USB; 1x 3.5mm audio) and 4 control stations (1x screen; 1x keyboard; 1x speakers/headphones).\nAny control station can connect to any computer — and even multiple control stations can be connected to the same computer.\nTo demonstrate how this is useful, the following is a common experiment workflow:\nEEG Recorder is displayed inside the cabin: as the technician flows the gel into the caps, they need to see which ones have good contact Eye Tracker is displayed inside the cabin: to run the calibration Presentation Machine (or Researcher's Laptop) is displayed inside the cabin: to display the actual experiment  Each control station has a Perixx keyboard (Periboard 409) that has 2 additional USB ports. One is used for a mouse; the other can be used by other USB response devices (joystick, etc). These are all routed, via the Gefen matrix, to the appropriate computer.\n Monitors The colored dots on the monitors match the Gefen matrix remote.\nRecording Monitor (Green/Input #1) Samsung SyncMaster SA450 The vertical orientation allows viewing many EEG channels simultaneously. Eye Tracking Monitor (Brown/Input #2) Requires a 4:3 ratio monitor Presentation Monitor (Blue/Input #3) Samsung SyncMaster 2233RZ In-Cabin Monitor (Red/Input #4) Samsung SyncMaster 2233RZ  The Samsung 2233RZ was specifically chosen because of a paper that measured its timing and found it to be favorable.\nTODO: link to 2233RZ paper\nTODO: explain refresh rate vs resolution and matrix\n Peripherals The following additional peripherals are available:\n2x USB Joysticks (1x \u0026quot;Flightstick Pro\u0026quot;; 1x \u0026quot;Fighterstick\u0026quot;) 2x 3-button 9-pin serial response box (custom) 1x 5-button 9-pin serial response box (custom) 1x 25-pin serial foot pedals (custom)  TODO: scroll device\n Zebris TODO: Describe and link: Zebris device\n "},{"id":14,"href":"/medusa-docs/tools/bids/","title":"BIDS","parent":"Tools","content":"The Brain Imaging Data Structure (BIDS) is a set of rules to organize and describe the data from neuroimaging and behavioral experiments. Following this practice makes it easier for scientists to work with each other's data, for both collaborative and reproducible-science purposes. A standard data layout also makes it easier to write analysis tools, and a growing number of tools (see BIDS Apps) require that input data be BIDS formatted.\nDo note that BIDS is under active development by the neuroimaging community. BIDS extension proposals (BEPs) are central to the governance for BIDS, and BEPs for other modalities and methods are continuously submitted, discussed, and integrated.\nResources These resources will assist you on your BIDS journey:\nthe BIDS specification a BIDS validator Tutorials, wikis, and templates — maintained by the community.   "},{"id":15,"href":"/medusa-docs/labs/g24_k010_behavioral/","title":"G24-K010: Behavioral","parent":"Experimental Labs","content":"This lab is operated shared among IPSY.\nFor questions, problems, or scheduling, contact Christina Becker.\nOverview The lab has three open cabins, a table with a divider for head-to-head experiments, and a desk for those overseeing experiments.\n Software Open Cabins These 3 computers all run Debian Jessie (8). All machines have Matlab (2012b), PsychoPy, and Psychtoolbox installed. All machines have been configured to match the timing/configuration requirements of both PsychoPy and Psychtoolbox.\nBecause of Matlab's network licensing, each machine is connected to the network.\n Head-to-Head These 2 computers run Windows 7 and have been configured so all non-essential services are disabled. Both machines have Presentation (multiple versions) installed — and also BrainVision Analyzer 2 (for instruction purposes).\nSince they are physically close to each other, both screens can easily be connected to the same computer for two-person experiments.\n   Monitors Open Cabins Each cabin is equipped with a Samsung S24C450 Head-to-Head These are non-standard monitors.   "},{"id":16,"href":"/medusa-docs/labs/g24_k012_eyetracker/","title":"G24-K012: Eye Tracker","parent":"Experimental Labs","content":"This lab is operated by the Pollmann Lab.\nFor questions, problems, or scheduling, contact Mikaella Sarrou.\nNOTE: This lab is due to be overhauled in 2018. Thus this documentation is limited — at best.\nOverview The lab is used primarily for behavioral and eye tracking experiments.\nTODO: mention back projected screen\n Software There are two Presentation Computers. One is a legacy, Windows XP machine (with \u0026quot;some version\u0026quot; of Matlab installed). The other runs a semi-standard Debian Jessie (8) setup with Matlab 2012b, PsychoPy, and Psychtoolbox installed. It has been configured to match the timing/configuration requirements of both PsychoPy and Psychtoolbox.\nThere is no KVM-Matrix, so switching between the two requires that all wires be disconnected and reconnected to the desired computer.\n Eye Tracker SR Research EyeLink 1000\nTODO: discuss camera speed, mount, etc\n Audio Speakers (of unknown manufacture) are available. Also available are Beyerdynamic DT-770 M headphones.\n Back Projected Screen TODO: Describe and link: big, back projected screen.\nTODO: Describe and link: projector\n Monitors The Presentation Monitor is a BenQ XL2410T.\n Peripherals The following peripherals are available:\n5-button, 25-pin serial VPixx technologies ResponsePixx VPX-ACC-3000 Handheld   "},{"id":17,"href":"/medusa-docs/tools/cli/","title":"The Command Line","parent":"Tools","content":"The shell (sometimes also called a terminal, console, or CLI) is an interactive, text based interface. If you have used Matlab or IPython, then you are already familiar with the basics of a command line interface.\nWhile the initial learning curve can be steep, the rewards are well worth it. Command line programs tend to be faster, more flexible, and more scalable than their GUI counterparts.\nBelow you can find a basic overview of how a command line program works, if you want a hand on tutorial, you can find good ones for example on Software Carpentry or HPC Carpentry\nSyntax Commands are case sensitive and follow the syntax of: command [options...] \u0026lt;arguments...\u0026gt;. The options modify the behavior of the program, and are usually preceded by - or --. For example:\nls -l test.txt  ls is the command. The option -l tells ls to display more information. test.txt is the argument — the file that ls is listing.\nEvery command has many options (often called \u0026quot;flags\u0026quot;) that modify their behavior. There are too many to even consider memorizing. Remember the ones you use often, and the rest you will lookup in their documentation or via your favorite search engine.\n Basic Commands pwd print the name of the folder you're currently in ls -lah \u0026lt;folder\u0026gt; list the contents of a folder, including hidden files (-a), and all their information (-l); print file sizes in human readable units (-h) [1] cd \u0026lt;folder\u0026gt; change to another folder cp \u0026lt;from\u0026gt; \u0026lt;to\u0026gt; copy a file cp -R \u0026lt;from\u0026gt; \u0026lt;to\u0026gt; copy a folder and its contents (-R) mv \u0026lt;from\u0026gt; \u0026lt;to\u0026gt; move/rename a file or folder rm \u0026lt;file\u0026gt; delete a file rm -Rv \u0026lt;folder\u0026gt; delete a folder and its contents (-R) and list each file as it's being deleted (-v) mkdir \u0026lt;folder\u0026gt; create a folder rmdir \u0026lt;folder\u0026gt; delete an empty folder chmod -R g+rwX \u0026lt;folder\u0026gt; give group members (g+) read, write (rw), and execute if already present for others (X) permissions for a folder and all of its contents (-R); see the Section on Permissions for more info. chown -R \u0026lt;username\u0026gt; \u0026lt;folder\u0026gt; change the owner of a folder and all of its contents (-R); see the Section on Permissions for more info. chgrp -R \u0026lt;groupname\u0026gt; \u0026lt;folder\u0026gt; change the group of a folder and all of its contents (-R); see the Section on Permissions for more info. echo \u0026quot;text\u0026quot; print text to the screen man \u0026lt;command_name\u0026gt; show the manual (documentation) for a command   Redirection Now that you know some of the basic shell commands, it's time to introduce some core shell concepts.\nThe output that commands print to the screen can also be redirected into a file or used as the input to an another program.\n\u0026gt; \u0026gt; writes the output of a command to a file. If the file already exists, it will overwrite the contents. For example:\necho 'Uhh, what kind of music do you usually have here?' \u0026gt; blues_brothers_reference.txt  Or, more practically, the output of a long running search.\nfind /home/data/exppsy -type f -name \u0026quot;*.fsf\u0026quot; -print \u0026gt; ffs_these_fsfs.txt   \u0026gt;\u0026gt; \u0026gt;\u0026gt; appends the output to a file. If the file doesn't exist, it will create it.\necho 'Oh, we got both kinds. We got country *and* western!' \u0026gt;\u0026gt; blues_brothers_reference.txt   | | (pipe) redirects the output of a command and uses it as the input for the next command. For example, the following will send the output of echo to sed, which replaces \u0026quot;stranger\u0026quot; with \u0026quot;good looking\u0026quot;.\necho 'Well hello there, stranger. \u0026lt;wink\u0026gt;' | sed 's/stranger/good looking/g'  More practically, the following command calculates the size of each file and folder in /tmp. The output is then sorted by size.\ndu -sh /tmp/* | sort -h    TODO: stdout and stderr\nTODO: explain clobbering and \u0026gt;|\n The Prompt When you first login on the command line, you are greeted with \u0026quot;the prompt\u0026quot;, and it will likely look similar to this:\naqw\u0026#64;medusa:~$  This says I am the user aqw on the machine medusa and I am in the folder ~, which is shorthand for the current user's home folder (in this case /home/aqw).\nThe $ sign indicates that the prompt is interactive and awaiting user input. [2] In documentation, $ is commonly used as a shorthand for the prompt, and allows the reader to quickly differentiate between lines containing commands vs the output of those commands. For example:\n$ ls -la wombats.txt -rw-rw---- 1 aqw psyinf 6 Nov 29 10:00 wombats.txt   Paths Let's say I want to create a new folder in my home folder, I can run the following command:\nmkdir /home/aqw/awesome_project  And that works. /home/aqw/awesome_project is what is called an absolute path. Absolute paths always start with a /, and define the folder's location with no ambiguity.\nHowever, much like in spoken language, using someone's full proper name every time would be exhausting, and thus pronouns are used.\nThis shorthand is called relative paths, because they are defined (wait for it...) relative to your current location on the file system. Relative paths never start with a /.\n. the current directory .. the parent directory ~ the current user's home directory  So, taking the above example again: given that I am in my home folder, the following commands all would create the new folder in the exact same place.\nmkdir /home/aqw/awesome_project mkdir ~/awesome_project mkdir awesome_project mkdir ./awesome_project  To demonstrate this further, consider the following: In my home directory /home/aqw I have added a folder for my current project, awesome_project/. Let's take a look at how this folder is organized:\n└── home └── aqw └── awesome_project ├── aligned ├── code └── sub-01 └── bold3T └── sub-02 └── bold3T ├── ... └── sub-xx └── bold3T └── structural └── sub-01 └── anat └── sub-02 └── anat ├── ... └── sub-xx └── anat  Now let's say I want to change from my home directory /home/aqw into the code/ folder of the project. I could use absolute paths:\ncd /home/aqw/awesome_project/aligned/code  But that is a bit wordy. It is much easier with a relative path:\ncd awesome_project/aligned/code  Relative to my starting location (/home/aqw), I navigated into the subfolders.\nI can change back to my home directory also with a relative path:\ncd ../../../  The first ../ takes me from code/ to its parent aligned/, the second ../ to awesome_project/, and the last ../ back to my home directory aqw/.\nHowever, since I want to go back to my home folder, it's much faster to run:\ncd ~   Globbing Most modern shells have powerful pattern matching abilities (often called globbing) that allows you to match the names of multiple files and/or directories. This is especially useful when running a command on many files at once. When globbing, the shell compares the pattern to files on the file system and expands the term to all matching file names.\nThe most basic pattern is *, which matches any number of any character(s).\nFor example, the following will list all files in the current directing ending in .txt:\nls *.txt  Or, lets you move a bunch of .jpg files into a folder:\nmv -v *.jpg annoying_instagram_food_pics/  Globbing can also nest through directories. For example, assuming a typical folder structure for subject data, you can list every subject's functional .nii.gz files for run 1:\nls sub-*/func/*_run-1_*.nii.gz  You can read about more about Pattern Matching in Bash's Docs.\n Permissions Every file and folder has permissions which determine which users are allowed to read, write, and execute it.\n$ ls -la wombats.txt -rw-rw---- 1 aqw psyinf 6 Nov 29 10:00 wombats.txt  The -rw-rw---- provides all the information about this file's permissions. The left-most - indicates whether it's a file, a folder (d), a symlink (l), etc. The rest are three tuplets of ---. The first tuplet is for the user, the second tuplet is for the group, the last tuplet is for all other users.\nThe above example shows that both the user (aqw) and the group (psyinf) have read and write permissions (rw-) to wombats.txt. All other users on the system have no permissions (---).\nLet's say I don't want others in the psyinf group to have permission to write to wombats.txt anymore.\n$ chmod g-w wombats.txt $ ls -lah wombats.txt -rw-r----- 1 aqw psyinf 6 Nov 29 10:00 wombats.txt  TODO: explain chmod 640 vs chmod g-w\nTODO: discuss (and show how to set UMASK)\nTODO: discuss user-private groups, sticky bit\nTODO: point to a more exhaustive explanation and/or man page\n Useful Commands ssh \u0026lt;username\u0026gt;\u0026#64;\u0026lt;servername\u0026gt; log into an interactive shell on another machine passwd change your password rsync -avh --progress from_folder/ \u0026lt;user\u0026gt;\u0026#64;\u0026lt;server\u0026gt;:/destination/folder sync/copy from a local folder to a folder on a remote server via SSH. Will preserve all permissions, checksum all transfers, and display its progress. grep -Ri \u0026lt;term\u0026gt; \u0026lt;folder\u0026gt; case-insensitive search for a term for all files under a folder htop overview of computer's CPU/RAM and running processes pip install --user \u0026lt;python_pip_package\u0026gt; install Python packages into your home folder sed -i \u0026quot;s/oops/fixed/g\u0026quot; \u0026lt;file\u0026gt; replace all occurrences of 'oops' with 'fixed' in a file wget \u0026lt;link\u0026gt; download a file find \u0026lt;folder\u0026gt; -type d -exec chmod g+s {} \\; find all folders underneath a directory and apply the \u0026quot;sticky bit\u0026quot; to them; see the Section on Permissions for more info. du -sh \u0026lt;folder\u0026gt; print how much disk space a folder uses cat \u0026lt;file\u0026gt; print the contents of a file to the screen head -n 20 \u0026lt;file\u0026gt; show the first 20 lines of a file tail -n 10 \u0026lt;file\u0026gt; show the last 10 lines of a file tail -f \u0026lt;file\u0026gt; print the last 10 lines of a file, and continue to print any new lines added to the file (useful for following log files) less \u0026lt;file\u0026gt; print the content of a file to the screen, one screen at a time. While cat will print the whole file, regardless of whether it fits the terminal size, less will print the first lines of a file and let you navigate forward and backward ln -s \u0026lt;target\u0026gt; \u0026lt;link_name\u0026gt; create a symlink (a shortcut)  TODO: sudo\nTODO: unzip/tar/gzip\nTODO: sshfs (different section/page?)\n Piping Fun du -sh ./* | sort -h calculate the size of each of the files and folders that are children of the current folder, and then sort by size find ./ -mmin -60 | wc -l find all files under the current directory that have been modified in the last 60 minutes, and then count how many are found ls -lah ~/ | less list all files in your home folder and display them one page at a time   Text Editors Text editors are a crucial tool for any Linux user. You will often find the need for one, whether it is to quickly edit a file or write a collection of analysis scripts.\nReligious wars have been fought over which is \u0026quot;the best\u0026quot; editor. From the smoldering ashes, this is the breakdown:\nnano Easy to use; medium features. If you're unsure of what to use, start with this. vim Powerful and light; lots of features and many plugins; steep learning curve. Two resources to help get the most out of vim are the vimtutor program (already installed on on the cluster) and vimcasts.org. emacs Powerful; tons of features; written in Lisp; huge ecosystem; advanced learning curve.   Shells Whenever you use the command line on a Unix-based system, you do that in a command-line interpreter that is referred to as a shell.\nThe shell is used to start commands and display the output of those commands. It also comes with its own primitive (yet surprisingly powerful) scripting language. [3]\nMany shells exist, though most belong to a family of shells called \u0026quot;Bourne Shells\u0026quot; that descend from the original sh. This is relevant, because they share (mostly) a common syntax.\nCommon shells are:\nbash The bourne-again shell (bash) is the default shell on many *nix systems (most Linux distros, MacOS). zsh The Z shell comes with many useful features, such as: shared history across running shells, substring search for history, smarter tab-completion, spelling correction, and better theming. tcsh The C shell (both csh and tcsh) is deprecated and should not be used. Some legacy systems use it, but is strongly encouraged to switch to either zsh or bash. Comparatively, C shell has a limited feature set. But most importantly, it is not a member of the Bourne family of shells, and thus uses a different syntax.  To determine what shell you're in, run the following:\necho $SHELL  TODO: history (up and searching), zsh history substring search\n Tab Completion One of the best features ever invented is tab completion. Imagine your spirit animal. Now imagine that animal sitting on your shoulder and shouting \u0026quot;TAB!\u0026quot; every time you've typed the first 3 letters of a word. Listen to your spirit animal's voice.\nTab completion autocompletes commands and paths when you press the Tab key. If there are multiple matching options, pressing Tab twice will list them.\nThe greatest advantage of tab completion is not increased speed (though that is a nice benefit) but rather the near elimination of typos — and the resulting reduction of cognitive load. You can actually focus on the task you're working on, rather than your typing.\nFor an example of tab-completion with paths, consider the following directory structure:\n├── Desktop ├── Documents │\u0026nbsp;\u0026nbsp; ├── my_awesome_project │\u0026nbsp;\u0026nbsp; └── my_comics │\u0026nbsp;\u0026nbsp; └── xkcd │ │ └── is_it_worth_the_time.png ├── Downloads  You're in your home directory, and you want to navigate to your xkcd comic selection in Documents/my_comics/xkcd. Instead of typing the full path error-free, you can press Tab after the first few letters. If it is unambiguous, such as cd Doc \u0026lt;Tab\u0026gt;, it will expand to cd Documents. If there are multiple matching options, such as cd Do, you will be prompted for more letters. Pressing Tab again will list the matching options (Documents and Downloads in this case).\nA visual example of tab-completion in action:\nThere are more sophisticated completion scripts, but they are not always enabled by default. For example, git add -p \u0026lt;TAB\u0026gt; will list only modified files. zsh can expand multiple levels at a time: cd d/m/x \u0026lt;TAB\u0026gt; will complete to cd Documents/my_comics/xkcd.\n [1]By default, file sizes are printed in Bytes. The -h flag changes this to units sane for human consumption. For example: 137216 would instead be listed as 134K. And for those brains rioting right now, remember, computers are binary, so 1K is 1024 bytes (210), not 1000 (103).    [2]The # symbol is commonly used to indicate a prompt with elevated permissions (such as the root user).    [3]As always, the man page (man bash) is a great reference. But if you're interested in acquiring a deep understanding of shell, then I highly recommend \u0026quot;Beginning Portable Shell Scripting\u0026quot; by Peter Seebach.    "},{"id":18,"href":"/medusa-docs/tools/dagman/","title":"DAGMan","parent":"Tools","content":"DAGMan is a HTCondor tool that allows multiple jobs to be organized in workflows. A DAGMan workflow automatically submits jobs in a particular order, such that certain jobs need to complete before others start running.\nOnce you are familiar with how to create, submit, and monitor HTCondor jobs, creating DAGMan workflows is relatively easy. The official documentation describes comprehensively the overall structure and available scripting of the dag-file.\nA simple dag file consists of a list of nodes (which are jobs plus optional pre- and post-processing scripts). In addition, their relationship can be specified via PARENT JobName CHILD JobName structures.\nExample A simple use-case for DAGMan is when wanting to run a set of jobs one after another, without having to submit each job manually once the previous one finishes (for example, when importing dicoms using datalad hirni-import-dcm or preprocessing multiple subjects using fmriPrep in sequence - both of these do not run well in parallel at the time of writing).\nTo achieve this two files are needed: a submit-file (e.g. my_job.submit) and a dag-file (e.g. my_workflow.dag).\nThe submit-file is a regular HTCondor submit file, but in addition, it can have special variables which will be set via the dag file on submission:\n#### The submit file - my_job.submit # The environment universe = vanilla getenv = True request_cpus = $(req_cpu) request_memory = $(req_mem) # Execution initial_dir = $ENV(HOME) executable = $ENV(HOME)/my_nature_worthy_analysis.sh # Job 1 # NOTE: arguments 2 and 3 are request_cpus and request_memory, respectively arguments = \u0026quot;$(subject) $(req_mem) $(req_mem)\u0026quot; log = $ENV(HOME)/logs/fortune_$(Cluster).$(Process).log output = $ENV(HOME)/logs/fortune_$(Cluster).$(Process).out error = $ENV(HOME)/logs/fortune_$(Cluster).$(Process).err Queue  In the above script, three additional, non-standard variables are included: req_cpu, req_mem, and subject. The first two are used to dynamically specify how many resources are needed for the job, as well as to be passed on to the analysis-script via the arguments of the job. The variable subject is only passed on to the analysis script.\nIn the associated dag-file, these variables can be set for all nodes (using VARS ALL_NODES ..) or for only specific nodes (VARS JobName ..). The example below shows how to set requirements for all jobs; the node names (a.k.a JobName 001, 002, and 003) are used to dynamically set the subject numbers.\n#### my_workflow.dag JOB 001 my_job.submit JOB 002 my_job.submit JOB 003 my_job.submit VARS ALL_NODES req_mem=\u0026quot;1000\u0026quot; VARS ALL_NODES req_cpu=\u0026quot;2\u0026quot; VARS ALL_NODES subject=\u0026quot;$(JOB)\u0026quot; CATEGORY ALL_NODES DummyCategory MAXJOBS DummyCategory 1  Finally, it is possible to limit the number of concurrently running jobs for each category of job. In this example, only one category (DummyCategory) is created and its MAXJOBS value is set to 1.\nSubmitting the dag-file using condor_submit_dag my_workflow.dag will add the workflow to condor's queue and execute all three jobs one after another, making sure that only one of them is running at a given time:\n-- Schedd: medusa.local : \u0026lt;10.0.0.100:9618?... \u0026#64; 02/11/20 20:58:05 OWNER BATCH_NAME SUBMITTED DONE RUN IDLE TOTAL JOB_IDS pvavra my_workflow.dag+1898 2/11 19:57 _ 1 _ 3 1898912.0 2 jobs; 0 completed, 0 removed, 0 idle, 2 running, 0 held, 0 suspended   "},{"id":19,"href":"/medusa-docs/tools/datalad/","title":"DataLad","parent":"Tools","content":"DataLad is a data management tool to share, search, obtain, extend, and version data.\nBeware that the underlying git annex calls (e.g. when calling datalad save) can be CPU-intensive if a dataset contains many files (e.g. a typical fMRI dataset). Thus, it is important to work on such datasets via an interactive job.\nResources The DataLad Handbook is the most comprehensive effort to document DataLad. However, it is still very much a work in progress as currently the content changes almost daily. DataLad Docs   Common Workflows TODO: Provide examples of a common IPSY workflows.\n "},{"id":20,"href":"/medusa-docs/labs/g24_k013_soundproof/","title":"G24-K013: Soundproof","parent":"Experimental Labs","content":"This lab is operated by the Pollmann Lab.\nFor questions, problems, or scheduling, contact Mikaella Sarrou.\nOverview The lab has one soundproof lab for eye tracking experiments. It is also equipped with a KVM matrix, which allows for nearly complete flexibility over which computer (EEG recorder, Eye Tracker, Presentation Machine, or researcher supplied Laptop) displays to any screen — and routes both audio and USB.\n Software The Presentation Computer runs Debian Jessie (8) with Matlab (2012b), PsychoPy, and Psychtoolbox installed. It has been configured to match the timing/configuration requirements of both PsychoPy and Psychtoolbox.\n Eye Tracker SR Research EyeLink 1000\nTODO: discuss camera speed, mount, etc\nCommunication with the eye tracker is done via the yellow Ethernet cable. The Presentation computer is already setup. If you need to communicate using your laptop, use the following settings to configure your NIC:\nAddress: 100.1.1.2 Netmask: 255.255.255.0 Gateway: 100.1.1.1   Speakers A portable, USB-rechargable, battery operated speaker is available.\n KVM Matrix The Gefen EXT-DVIKVM-444DL KVM Matrix (datasheet; manual) is the key piece that makes it possible to use all the computers, screens, USB peripherals, and audio devices — in all the needed combinations. It is also a DVI amplifier, enabling reliable signal for the longer cable runs into the EEG cabin.\nThe matrix can connect to 4 computers (1x DVI; 1x USB; 1x 3.5mm audio) and 4 control stations (1x screen; 1x keyboard; 1x speakers/headphones).\nAny control station can connect to any computer — and even multiple control stations can be connected to the same computer.\nTo demonstrate how this is useful, the following is a common experiment workflow:\nEye Tracker is displayed inside the cabin: to run the calibration Presentation Machine (or Researcher's Laptop) is displayed inside the cabin: to display the actual experiment  Each control station has a Perixx keyboard (Periboard 409) that has 2 additional USB ports. One is used for a mouse; the other can be used by other USB response devices (joystick, etc). These are all routed, via the Matrix, to the appropriate computer.\n Monitors The colored dots on the monitors match the Gefen matrix remote.\nPresentation Monitor (Green/Input #1) iiyama G-MASTER GB2488HSU-B2 Eye Tracking Monitor (Brown/Input #2) Requires a 4:3 ratio monitor In-Cabin Monitor (Red/Input #4) iiyama ProLite GB2488HSU-B1  The In-Cabin Monitor is wall mounted with an adjustable arm and swivel. This allows the monitor height and depth to be adjusted for experiments which require different visual-fields.\nA laser distance meter and level is available (on the shelf near the doorway) to verify that the screen is positioned correctly.\nTODO: explain refresh rate vs resolution and matrix\n Peripherals The following peripherals are available:\n8-button, USB Cedrus RB-830 Response Pad 5-button, 25-pin serial Psychology Software Tools 200A Response Box 6-button, 25-pin serial Cedrus RB-600 Response Box   "},{"id":21,"href":"/medusa-docs/tools/git/","title":"Git","parent":"Tools","content":"Git enables you to track the changes made to files over time — specifically: what changed, by whom, when, and why. It also gives you the capability to revert files back to a previous state. Over time, as your project evolves, you can edit your files with confidence knowing that at any point you can look back and recover a previous version.\nInstall Debian/Ubuntu sudo apt install git   macOS Download the installer at: https://git-scm.com/download/mac Windows Download the installer at: https://git-scm.com/download/win   Configure Once Git is installed, configure it with your name and email address. This lets Git know who you are so it can associate you with the commits you make.\ngit config --global user.name \u0026quot;Wiggly McWidgit\u0026quot; git config --global user.email wiggity-wiggity-wack\u0026#64;example.com   Repository Anatomy A git repository is just a folder that git is tracking the changes in. All of the behind-the-scenes information and metadata that allows git to perform its magic is stored in the .git/ folder in top folder of your project.\nThere are two types of files for git: tracked and untracked files. Tracked files are files that git is aware of (via git add). Only tracked files are considered part of the repository, and thus only tracked files have the special powers-of-git bestowed upon them: history, commit messages, and ability to share/merge history through git push and git pull. Untracked files are just the normal file-experience: no history, no reverting, no easy sharing, etc.\nGit has three different states for tracked files:\nmodified The file has been modified. The changes are not (yet) part of your project's history. staged Modified content which is staged to be committed, but is not yet committed. The staging step is so that you can review whether the changes should be committed and to be able to stage multiple changes/files for a commit. Content is staged using git add/git add -p. committed The content is stored in your history. Content is committed using the git commit command.   Basic Commands git init Creates a repository in this folder. Note, no files are tracked (git add-ed yet. git clone \u0026lt;url\u0026gt; | \u0026lt;user\u0026#64;server:/path/to/repo.git\u0026gt; Makes a full copy of an existing git repository — all files, folders, changes, history, etc. git status Lists which files are in which state — if there have been changes made, new files added or deleted, etc. git add \u0026lt;file\u0026gt; To begin tracking a new file. Once you run git add, your file will be tracked and staged to be committed.\ngit add -p Review the changes you've made to tracked files, and choose which changes will be staged.   git commit Commits all the staged changes (see git add). It will prompt you for a commit message, which should be a terse but descriptive note about the changes contained in the commit. These commit messages are your project's history. git rm \u0026lt;file\u0026gt; Deletes the file, and stages the deletion. Note that the file and its contents remain in the project history, and can be recovered. git mv \u0026lt;file-from\u0026gt; \u0026lt;file-to\u0026gt; Moves/renames a file and stages the rename. git log Lists your commit history. It's not as user-friendly or easy-to-navigate as tig. tig A text-mode interface for git that allows you to easily browse through your commit history. It is not part of git and needs to be installed (apt install tig for Debian/Ubuntu; Homebrew instructions for macOS) git push Push your local changes to another repository, for example on GitHub. git pull Pull changes from another repository to your local repository.   GitHub GitHub is an online platform where you can store and share your projects; it is especially well suited for working on a project with several other people. It acts as a central place where everyone can access/contribute to the project and offers several useful tools (issues, wikis, project milestones, user management, etc) that make collaboration simple and easy.\nTo create a profile, go to GitHub, and from there, follow the prompts to create your account.\n GitLab GitLab is much like GitHub, but is open source and can be hosted by anyone.\n Pull Requests Platforms like GitHub and GitLab enable pull requests (called a merge request on GitLab) to propose and collaborate on changes to a repository. A typical pull request workflow looks like this:\nOn the platform of your choice, fork the repository you want to contribute to (commonly called \u0026quot;upstream\u0026quot;). This creates a copy of the upstream repository under your user account, to freely make changes without affecting the original project. Clone your fork of the repository on your local machine. Create a new branch in your local clone (git checkout -b mybranch master). Make your changes locally and commit them. Push your changes to your fork. On GitHub/GitLab, go to your fork, select the new branch, and create a pull request to the upstream repository.  The above works well for your first PR. But what if you worked on other projects for a few months, upstream development has continued, and now you want to propose another change to the current upstream code?\nAdd the upstream repository as a remote on your local clone (git remote add upstream \u0026lt;url\u0026gt;). Note, this only has to be done once. Fetch the latest changes from upstream (git fetch upstream). Create a new branch in your local clone, based on upstream's master branch (git checkout -b mybranch upstream/master). Then proceed as usual, making your local changes, committing, pushing to your fork, and then opening a PR through the web UI.  The following diagram can help visualize how the above steps work together.\n Resources GitHub offers an interactive Git tutorial that is a great starting point for beginners.\nAtlassian provides a nice overview of both the forking workflow. and Pull Request workflow that are common in our projects and the wider Open Source community.\nThe free Pro Git Book covers just about everything Git has to offer using clear and easy-to-understand language. It starts with the basics, but builds up to some of Git's more complex features.\nIf you like video tutorials, the Intro to Git and GitHub and The Basics of Git and GitHub videos are worth watching to learn about the basics of Git and GitHub and want a step-by-step explanation of how to get started.\nFor any questions you might have about using GitHub, see GitHub Help.\nThe Git Reference Manual is the official docs for Git. It has all the information you could want to know about Git, but is pretty dense and better suited for intermediate and advanced users.\n "},{"id":22,"href":"/medusa-docs/tools/htcondor/","title":"HTCondor","parent":"Tools","content":"HTCondor (also known as condor) is a job scheduler. It is powerful, but conceptually quite simple. Condor:\nruns the jobs you tell it to finds places to run those jobs makes sure everyone has fair access to resources  There are two aspects when teaching people how to use Condor:\nUsing Condor itself (useful commands, the .submit file). This is relatively easy, and is what this document focuses on. Understanding the problems your scripts are trying to solve, and how to break those up into conceptually discrete steps and units. Put another way: how to not use the cluster like one big laptop and instead like thousands of tiny desktops. For many people, this is the not so easy part.  A Simple Sample Let's keep things simple. You want to run the command fortune using condor. Just one job. Here's how we do so:\ncreate a file called fortune.submit defining your job:\n# The environment universe = vanilla getenv = True request_cpus = 1 request_memory = 1G # Execution initial_dir = $ENV(HOME) executable = /usr/games/fortune # Job log = $ENV(HOME)/logs/fortune_$(Cluster).$(Process).log output = $ENV(HOME)/logs/fortune_$(Cluster).$(Process).out error = $ENV(HOME)/logs/fortune_$(Cluster).$(Process).err Queue   create a folder for the logs:\nmkdir ~/logs   submit the job to condor\ncondor_submit fortune.submit   watch the queue (the job will move from IDLE, to RUN, and then then will disappear, meaning it has finished).\ncondor_q   read the output file containing your fortune\ncat ~/logs/fortune_*.out     Anatomy of .submit To accomplish more than the simple example above, you'll need to understand the anatomy of a submit file.\nA .submit file describes the jobs (commands and their arguments) that condor will run, the environment they will run in, and the needed hardware resources (RAM, CPU).\nThis example defines two jobs, and this time with an argument. One job outputs the calendar for 1985 and the second job for 1986.\n# The environment universe = vanilla getenv = True request_cpus = 1 request_memory = 1G # Execution initial_dir = $ENV(HOME) executable = /usr/bin/ncal # Logs log = $ENV(HOME)/logs/$(Cluster).$(Process).log output = $ENV(HOME)/logs/$(Cluster).$(Process).out error = $ENV(HOME)/logs/$(Cluster).$(Process).err # Job 1 arguments = \u0026quot;1985\u0026quot; Queue # Job 2 arguments = \u0026quot;1986\u0026quot; Queue  Breaking this into sections:\n universe = vanilla getenv = True  The first two lines you likely will never need to change. universe declares the type of Condor environment used, and getenv tells Condor to copy environmental variables from your execution environment to the compute nodes. Unless you know what you're doing, keep these lines unchanged.\n request_cpus = 1 request_memory = 1G  Often people don't know how much RAM their job will consume. In that case, make an educated guess, and then submit a single job. When it completes, check its .log file. It contains information about the memory usage of the job.\n initial_dir = $ENV(HOME)  This is the directory that Condor will cd to when starting your job. All paths are relative to this starting directory (unless they are absolute paths, i.e. starting with a /). In this case, it is your user's home folder.\n executable = /usr/bin/ncal  Next comes the executable. It is common for users to simply enter the command name. This is often wrong. Re-read the description above for initial_dir, and you will see that if executable is set to ncal, it would try to run /$HOME/ncal. This is usually what you want when you're executing a script you've written, but it's not what you want when executing a system utility. In that case, use an absolute path.\n # Logs log = $ENV(HOME)/logs/$(Cluster).$(Process).log output = $ENV(HOME)/logs/$(Cluster).$(Process).out error = $ENV(HOME)/logs/$(Cluster).$(Process).err  The log files store information about the job. The $(Cluster) and $(Process) macros supply the job ID, and are used here to create unique log files for each job.\nlog: for information about the condor job (duration, memory usage, the machine it ran on, etc) output: anything the job writes to stdout error: anything the job writes to stderr   # Job 1 arguments = \u0026quot;1985\u0026quot; Queue  The arguments are what is passed to the executable.\nThen comes Queue. This means \u0026quot;submit a job\u0026quot;. The state of all variables up to this point will be submitted as a job. We will soon see, with the second job, how this is powerful.\n # Job 2 arguments = \u0026quot;1986\u0026quot; Queue  The arguments variable is overwritten, and then we Queue another job. It's as simple as that. In this case, jobs 1 and 2 are identical except for their arguments.\nYou may wonder how the log files are unique for each job if we havn't redefined them. This is because we're using condor macros to refer to the job ID. That being said, it is quite common to redefine the log files for each job, containing more human-useful information.\n   Generating a .submit Condor's strength is not running one job at a time. Its strength is running thousands of jobs at a time, and no one in their right mind writes such submit files by hand. A simple script is used to generate them.\nWe'll do a repeat of the above jobs, but this time outputing calendars for the last ~1,000 years.\n#!/bin/sh # v3.0 logs_dir=~/logs # create the logs dir if it doesn't exist [ ! -d \u0026quot;$logs_dir\u0026quot; ] \u0026amp;\u0026amp; mkdir -p \u0026quot;$logs_dir\u0026quot; # print the .submit header printf \u0026quot;# The environment universe = vanilla getenv = True request_cpus = 1 request_memory = 1G # Execution initial_dir = \\$ENV(HOME) executable = /usr/bin/ncal \\n\u0026quot; # create a job for each subject file for year in $(seq 1000 1999); do printf \u0026quot;arguments = ${year}\\n\u0026quot; printf \u0026quot;log = ${logs_dir}/y${year}_\\$(Cluster).\\$(Process).log\\n\u0026quot; printf \u0026quot;output = ${logs_dir}/y${year}_\\$(Cluster).\\$(Process).out\\n\u0026quot; printf \u0026quot;error = ${logs_dir}/y${year}_\\$(Cluster).\\$(Process).err\\n\u0026quot; printf \u0026quot;Queue\\n\\n\u0026quot; done  Let's run the script and make sure that the output looks sane (if it fails with \u0026quot;permission denied\u0026quot;, you probably forgot to mark it as executable by using chmod +x).\n./ncal_submit_gen.sh  If everything looks good, then it's time to submit the jobs directly to condor.\n./ncal_submit_gen.sh | condor_submit  And you just submitted 1,000 jobs to condor.\nExamples A collection of additional examples of submit scripts for example for Python can be found in the htcondor-examples git repo.\n  Interactive Jobs To work interactively on a compute node instead of the head node, there are two ways:\nrun a default interactive job with condor_submit -interactive, i.e. without specifying any submit-file. submitting a job which can specify additional, non-default values.  An example submit file for an interactive job is:\n# The environment universe = vanilla getenv = True # Auto-exit after being idle for 2 hours (7200 seconds) # If you are tempted to set this to a high value: just don't. Jobs sitting # idle block other users from executing jobs. Don't be that person. environment = \u0026quot;TMOUT=7200\u0026quot; # Required Resources request_cpus = 1 request_memory = 4G # Execution initial_dir = $ENV(HOME) executable = /bin/bash # Logs log = $ENV(HOME)/logs/$(Cluster).$(Process).log output = $ENV(HOME)/logs/$(Cluster).$(Process).out error = $ENV(HOME)/logs/$(Cluster).$(Process).err # Job - spawn one instance Queue  NOTE: An interactive session is blocking the requested CPU(s) and memory for your use, potentially preventing others to run their jobs. If you do not plan to work within the next 1-2 hours using the interactive session, exit it and resubmit a new interactive job later.\nFor long-running processes (e.g. importing DICOMs using datalad-hirni), you should start this interactive job from a tmux session. That is, you should log into the head node as usual, start tmux and then start the interactive session. This way, the interactive session will be part of your tmux session, which you can detach and re-attach later.\n Useful Commands List all slots (available and used) and their size condor_status   Submit a job/job cluster condor_submit \u0026lt;file.submit\u0026gt;   To gain access to an interactive shell on a node — even with a GUI. condor_submit -interactive \u0026lt;file.submit\u0026gt;   Summary of your jobs in the queue condor_q   All of your running jobs and which machine they are on condor_q -nobatch -run   All jobs from all users in the queue condor_q -nobatch -allusers   See why job is on hold condor_q -hold   Explain why a job is in a particular state condor_q -better-analyze \u0026lt;jobid\u0026gt;   Remove jobs from the queue condor_rm \u0026lt;username\u0026gt; # remove all jobs for this (your) user condor_rm \u0026lt;clusterid\u0026gt; # remove all jobs belonging to this cluster condor_rm \u0026lt;clusterid\u0026gt;.\u0026lt;jobid\u0026gt; # remove this specific job   User statistics, priority, and priority factor condor_userprio --allusers   For those who are more familiar with Sun's GridEngine, Condor provides condor_qsub. condor_qsub     Documentation The official Condor documentation is long, but comprehensive. If you have questions, their docs are a great resource. Pay special attention to the sections on Submitting a Job and Managing a Job. Medusa is quite old and thus there is still an old htcondor version running (version 8.6.8) for which no documentation exists anymore.\n "},{"id":23,"href":"/medusa-docs/labs/EXFA_skyra/","title":"EXFA: Skyra","parent":"Experimental Labs","content":"NOTE: This documentation is in progress.\nOverview TODO: add contact info\n Software There is one presentation computer, provided by the biopsych lab. It runs both Windows XP and Debian Jessie.\nDebian This is the standard experiment machine setup. Matlab (2012b), PsychoPy, and Psychtoolbox are installed. The machine has been configured to match the timing/configuration requirements of both PsychoPy and Psychtoolbox. Windows An ancient Windows XP install. It is, for obvious reasons, deprecated, but it is functional. Presentation is installed.   Scanner 3 Telsa Siemens Magnetom Skyra\nTODO: discuss scanner triggers\n Projector TODO: Describe and link: projector\n Peripherals TODO: Describe parallell response box\n "},{"id":24,"href":"/medusa-docs/tools/python/","title":"Python","parent":"Tools","content":"Debian Packages If you're running Debian, it's often easiest to use the official Debian packages (when present) to install python modules. Search for them via apt. For example:\napt search mvpa2  Once you've found the package, install it:\napt install python-mvpa2  If you can't find a Debian package for the module you want installed, then you can to install it using pip — preferably in a virtual environment (see below).\n Virtual Environments Virtual environments (AKA \u0026quot;venvs\u0026quot;) allow you to create isolated environments for Python. These environments still have access to the full filesystem, but their \u0026quot;Python World\u0026quot; is their own sandbox to play in, and is completely independent of everything else.\nThe advantages of this isolation are numerous (tidiness, one project's dependencies won't affect others, ease of troubleshooting, etc). Using venvs should be your default mode of operation.\nVirtual environments can be created anywhere on the filesystem, but I like to keep them all together in a hidden folder called .venvs in my home directory.\nTo create a venv for your new hyperalignment project, run the following:\npython3 -m venv ~/.venvs/hyperHyper  NOTE: Python 2.7 users will need to use the virtualenv command (e.g. virtualenv ~/.venvs/hyperHyper)\nTo activate your new venv run:\nsource ~/.venvs/hyperHyper/bin/activate  Your shell's prompt will change to denote the venv you are in. Now you can install whatever packages you need (using pip3 install); they will all be stored in ~/.venvs/hyperHyper and will only be available when this venv is activated.\nWhen you're done, deactivating is as simple as running:\ndeactivate   IPython IPython is an interactive shell to compute Python code, similar to the Bash shell or the Matlab prompt. IPython features tab-completion, command history retrieval across sessions, dynamic object introspection, and magic commands that provide some nice quality-of-life syntactical sugar. To begin an IPython session, simply run:\nipython   Resources Interactive Book: Foundations of Python Programming A \u0026quot;projects first\u0026quot; approach that focuses on building things using Python rather than focusing on the language itself. Book: Learn Python the Hard Way Popular with good content. People either enjoy or strongly dislike the book's approach of typing out every exercise, embracing failure, and working through problems. Book: Python Crash Course A good go-to book for learning Python. Website: The Python Tutorial The official tutorial from the Python Project.   "},{"id":25,"href":"/medusa-docs/tools/R/","title":"R","parent":"Tools","content":"Debian Packages If you're running Debian, it's easiest to use the official Debian packages (when present) to install R packages. Search for them via apt. For example:\napt search tidyr  Once you've found the package, install it:\napt install r-cran-tidyr  If you can't find a Debian package for the R module you want installed, then you can install it directly from CRAN (see below).\n CRAN CRAN is the main repository for community projects.\nInstalling packages from CRAN can range from dull, to thrilling, to aggravating beyond all belief. It will quickly become apparent which adventure you have chosen.\nIt is best to install packages to your home folder; this avoids the need for admin privileges.\nFirst create a directory for the packages:\nmkdir -p ~/.R/library  Then tell R you want to use this folder:\necho 'R_LIBS_USER=\u0026quot;~/.R/library\u0026quot;' \u0026gt; ~/.Renviron  Packages from CRAN can now be installed using ìnstall.packages()` and will be installed into ~/.R/library. For example, to install packrat, start R and then run:\n\u0026gt; install.packages(\u0026quot;packrat\u0026quot;)   Packrat Packrat allows you to create isolated environments for R projects, similar to Python's \u0026quot;virtualenv\u0026quot;. It is not installed by default, so you will need to follow the above instructions to install it.\nTo use packrat for your new stats project called \u0026quot;probably\u0026quot;, we first need to create the project folder:\nmkdir -p ~/.renvs/probably  Now, start R and initialize the folder as a packrat project:\n\u0026gt; packrat::init(\u0026quot;~/.renvs/probably\u0026quot;)  Now you can install whatever packages you need (using install.packages()); they will all be stored in ~/.renvs/probably and will only be available when this packrat instance is activated.\nWhen you're done, deactivate it:\n\u0026gt; packrat::off()  If you start R from the project's packrat folder (~/.renvs/probably in this case), packrat will start the environment automatically.\n Resources Book: Statistical Rethinking Bayesian statistics and general intellectual superiority. (english) Book: Discovering Statistics Using R A good, standard book with a narrative. (english) Book: Grundlagen der Datenanalyse mit R Encyclopedia style, covering all standard statistics. (german)   "},{"id":26,"href":"/medusa-docs/tools/sixel/","title":"sixel","parent":"Tools","content":"Sixel allows displaying graphics at the command line; it's technology from the 80s that never made it — until quite recently.\nA picture is worth a thousand words:\nUtilities img2sixel niicat (not yet installed on Medusa; users should install in a venv for now)   Setup Currently, very few terminals support sixel.\nmacOS Download and install iTerm2. The built-in terminal does not support sixel. Linux xterm is the recommended terminal for using sixel. None of the following popular terminals have in-tree support: GNOME Terminal, Konsole, urxvt, st.\nIf you're using the IPSY dotfiles then everything should \u0026quot;just work\u0026quot;. Otherwise, you will need to adjust your .Xresources settings.\n   Testing A test image is provided as part of the IPSY dotfiles:\ncat ~/.dotfiles/test/snake.six   "},{"id":27,"href":"/medusa-docs/tools/ssh/","title":"SSH","parent":"Tools","content":"SSH is used to securely login to a machine over the network. It is most commonly used to start an interactive shell on the remote server, but many commands (such as rsync and scp) are capable of using the SSH protocol to securely transfer bulk data.\nSSH comes installed by default on all modern machines (Linux, macOS, and Windows 10).\nUsing SSH Logging into a remote machine is quite simple with SSH:\nssh username\u0026#64;medusa.ovgu.de  SSH on Windows How to install the SSH Client on Windows 10\nPress the Search button and type “Optional feature” -\u0026gt; Click the top result, which should read, “Add an optional feature”. Click “Add a feature” in Settings Install the Windows OpenSSH Client -\u0026gt; Type “SSH” in the optional features search bar, then tick the entry that reads “OpenSSH Client”. Finally, click the “Install” button at the bottom of your Window. The process will take a few seconds to complete and shouldn’t require a restart.  How to Use SSH in Commands in Windows 10\nOpen Command Prompt (or Powershell) -\u0026gt; Press Start and then type “Command Prompt”. Click the top result. Run the SSH command to view its usage guide -\u0026gt; Command prompt will return a full list of options and syntax for you to use as you require. Connect to your server via your Windows Open SSH client -\u0026gt; In most cases, you won’t need the above options to connect to your SSH server.    If it is the first time that you have connected to this server with SSH, you will receive a prompt similar to the following:\nThe authenticity of host 'medusa.ovgu.de (141.44.17.54)' can't be established. ECDSA key fingerprint is SHA256:fgvO3iB0fUsVjbrXLhg8h8ZPZdXa55rnwR+9P72O7oU. Are you sure you want to continue connecting (yes/no/[fingerprint])?  Type \u0026quot;yes\u0026quot; to confirm the fingerprint (please see the explanation of fingerprints below).\nAuthenticate, and you now have an interactive session on the remote machine.\n Keys SSH also supports key-based authentication, which is much more secure than password authentication.\nIt is a common misconception that using keys means that you don't need a password. Though a key instead of a password is used to authenticate to the server, a password is used to protect the key itself on your system (it is possible to create keys that are not password protected, but it is considered poor practice).\nProtecting your key with a password is important. Otherwise, if someone accesses your computer, they will gain access to every system that uses that key. That's bad (technical term).\nIf you don't yet have an SSH key, generate one by running the following, and follow the prompts:\nssh-keygen -t rsa -b 4096  Once you have a key, it can be copied to a server using ssh-copy-id. For example:\nssh-copy-id username\u0026#64;medusa.ovgu.de   X Forwarding Graphical programs run on the remote server can be displayed on your local machine using a feature called X Forwarding. To enable this, use the -X flag. For example:\nssh -X username\u0026#64;medusa.ovgu.de  However, X Forwarding comes with one major caveat: it is very sensitive to latency, so it is only practical to use when on the same wired network as the server (i.e. on campus).\nX Forwarding also requires that your local machine has X installed. This is the default on Linux systems, but macOS systems need to install XQuartz [1] while Windows 10 systems need VcXsrv installed via WSL.\n Jump Hosts If you want to connect to a server that is on a private network, you will want to use a Jump Host.\nTo explain, let's say we're robbing a bank (sometimes called \u0026quot;self financing\u0026quot; in academia). The server vault isn't publicly available, but lobby is, so we're going to connect to it first and use it as a jump host.\nFor example:\nssh -J username\u0026#64;lobby username\u0026#64;vault  This will first connect to lobby, and then connect to vault.\nThis is more convenient than manually SSHing (ssh lobby followed with ssh vault), but more importantantly, it allows for the SSH keys from the original computer to be used to authenticate to both servers. Otherwise, you would need to store a copy of your keys on lobby, which is unsafe. They're called keys for a reason: keep them secret; keep them safe.\n Agents An agent (e.g. ssh-agent) can be used to remember the password to unlock your key, usually with a timeout. This can be quite convenient when connecting frequently to servers.\nTODO: Discuss agents. ssh-agent is most often suggested, but its behavior is non-obvious, especially when compared to gpg-agent (which is an option when using RSA keys). On macOS, Apple keychain can be used.\n Fingerprints Each server has a unique fingerprint that identifies it.\nIn theory, when first connecting to a server, users should take great care to verify that the fingerprint offered is authentic by confirming it against a trusted copy via a different (preferably analog) communication channel (e.g. phone). This allows you to be certain that you are indeed connecting to the server that you think you are, and that no one is attempting a Man-in-the-Middle attack.\nIn reality (and unsurprisingly), the majority of users do not perform such steps. However, fingerprints still have value, because SSH will notify you if the server's fingerprint changes. This helps protect against future MITM attacks. [2]\nYour SSH client maintains a list of server fingerprints in the ~/.ssh/known_hosts file.\n Config SSH has many powerful options. If you want to use different keys for different hosts, use jump hosts automatically when connecting to certain hosts, etc, then you should read man ssh_config. These options are all set in the ~/.ssh/config file.\n [1]There have been some problems with recent XQuartz releases, but users have reported that version 2.7.7 works best for them. It is recommended to use that version until 2.7.12 is released.    [2]As always, there are many details and nuances that make this technically untrue. But it is a reasonable approximation for what a user's understanding of the situation should be.   Authenticate, and you now have an interactive session on the remote machine.\n Tutorial: (https://winbuzzer.com/2021/08/25/how-to-enable-and-use-ssh-commands-on-windows-10-xcxwbt/)  "},{"id":28,"href":"/medusa-docs/tools/tmux/","title":"tmux","parent":"Tools","content":"tmux is a tool to manage terminal sessions. For those familiar with screen, tmux is a more featureful and better maintained alternative.\nThe primary functionality discussed here is tmux's ability to detach and re-attach sessions, without affecting the programs running within the session. When using unstable network connections (such as bad wifi), this can save you significant frustration. If the VPN or SSH connection drops, you can just reconnect and reattach the tmux session without losing any of your work.\ntmux has many other useful features, including displaying multiple terminals at once by splitting the window into panes. In addition to the man page (man tmux), the The Tao of Tmux (especially chapters 7 and 11) is a popular reference. The Linux Academy also offers a convenient tmux cheat sheet, to help with frequently used tmux commands and keybindings.\nExample As a practical example, let's run tmux on medusa:\naqw\u0026#64;medusa:~$ tmux  And to celebrate creating our first tmux session, let's run cmatrix:\ncmatrix  That's one Keanu \u0026quot;whoa\u0026quot;. Our terminal is now state-of-the-art 1999.\nSessions in tmux can be detached and reattached, without interrupting the program running inside. To detach, type ctrl + b, and then type d. Your session is detached, and you're back at the prompt. When we reattach, cmatrix will still be running, right where we left it:\ntmux attach  Let's detach again from our current session (ctrl + b then d), and create another session. This one we'll name, for convenience (and style):\ntmux new -s inigo_montoya  And we're in a new tmux session, this one named \u0026quot;inigo_montoya\u0026quot;. Let's detach (you should be getting good at this now). At the prompt, list the running tmux sessions:\naqw\u0026#64;medusa:~$ tmux list-sessions 0: 1 windows (created Sun Apr 28 13:09:06 2019) [119x39] inigo_montoya: 1 windows (created Sun Apr 28 14:00:29 2019) [119x39]  Session 0 is the first tmux session we created (with cmatrix running in it). inigo_montoya is the session we just created. To attach a specific session, run:\ntmux attach -t inigo_montoya  Sessions can be quit either by typing exit from within the session, or with kill-session:\ntmux kill-session -t 0 tmux kill-session -t inigo_montoya   "},{"id":29,"href":"/medusa-docs/services/","title":"Services","parent":"Welcome","content":"In addition to the computational cluster and experimental labs, IPSY and the wider OvGU community provide a range of services.\n "},{"id":30,"href":"/medusa-docs/services/communication/","title":"Communication","parent":"Services","content":"These are the primary methods of communication in the lab:\nOvGU Email Once your account is setup, you can access your email via many ways:\nWebmail via email client of your choice. A detailed description on the configuration can be found here   Mailing Lists exppsy\u0026#64;ovgu.de Subscribe to exppsy neuropsy-list\u0026#64;ovgu.de Subscribe to neuropsy biopsy-l\u0026#64;ovgu.de Subscribe to biopsy brazi-l\u0026#64;ovgu An IPSY-wide mailing list that emails directly to the above three lists, plus members of other IPSY labs which don't have a mailing list. Subscribe to brazi-l   Mattermost The faculty for computer science hosts a mattermost instance to which you can register and join an existing team. For that a team admin has to invite you to it. Team admins currently are: Nico Marek, Peter Varvra and Manuela Kuhn\nEvery team has two types of channels:\npublic: everybody can join private: one can only join after an invitation of a channel member  By default every team has two public channels: \u0026quot;Off-Topic\u0026quot; and \u0026quot;Town Square\u0026quot;.\nIn addition one-to-one-communication between people is also possible via \u0026quot;direct message\u0026quot;.\nA more detailed explanation on how to use mattermost can be found on the official mattermost documentation.\n "},{"id":31,"href":"/medusa-docs/services/hosted/","title":"Hosted","parent":"Services","content":"Webspace Web servers are available for:\nLab/Project Websites such as studyforrest.org, howdoyouscience.net, etc Data Distribution such as psydata.ovgu.de Personal Websites Every IPSY user has a public_html/ folder in their home directory on kumo.ovgu.de. Any files placed in that folder will be made available at http://kumo.ovgu.de/~\u0026lt;username\u0026gt;/.   DNS Some projects have their own domain names, but the majority of systems will live under the following namespaces.\nipsymd.de For convenience and brevity. As this name is new, only a few services use it, but in the end, most internal services will migrate to it. ovgu.de For official, outward facing services that should display the full OvGU branding (website, major projects, etc).   Debian Repository IPSY-specific packages (scripts, configuration) and license restricted software (Freesurfer, Matlab, etc) is available. To add the repo to your Debian machine, run the following:\nprintf \u0026quot;deb http://kumo.ovgu.de/debian stretch main\\n\u0026quot; | sudo tee /etc/apt/sources.list.d/ipsy.sources.list wget -O- http://kumo.ovgu.de/debian/ipsy_apt.gpg.key | sudo apt-key add - sudo apt update sudo apt search ipsy-  Due to the restrictive licensing, this repository is only available to machines with a wired connection in the IPSY offices or via VPN.\n Dotfiles An IPSY dotfiles repository is provided (ssh://medusa.ovgu.de:/home/git/dotfiles.git), containing a collection of config files with sane defaults to enable a baseline, reasonably featured command line experience.\nThe README file in the repository contains instructions on how to use dotfiles.\n JupyterHub (retired) The IPSY JupyterHub instance is now retired. The URZ, as a result of our successful trial, will host a JupyterHub instance and make it available for university use sometime in 2020.\nTODO: Add link/contact info here for the URZ instance.\n OwnCloud (EOL) The OwnCloud deployment is now deprecated and no new users are permitted. Existing users are being migrated to other solutions.\n "},{"id":32,"href":"/medusa-docs/services/network/","title":"Network","parent":"Services","content":"Wired Network Most network jacks are activated. If you need network access and the jack isn't active, contact Nico Marek and he will ask for it to be enabled.\n Wireless Network There are many WiFi networks available on campus. We recommend the following networks:\neduroam Uses your OvGU email address and password to authenticate. Can be used at any institution participating in the eduroam network. OvGU-802.1X Uses your OvGU account. Is considered part of the OvGU network, and can access intranet resources.   VPN VPN access allows you to remotely connect to resources that are only available from within the OvGU network (such as licensing servers, journal access, etc).\nVPN Type: Cisco IPSec host: vpn.ovgu.de user: \u0026lt;your ovgu account\u0026gt; (same one to authenticate for email) password: \u0026lt;your password\u0026gt; group-name: vpn1 shared secret: vpn1  In general, it is easiest to use your OS's built-in VPN support. However, Cisco does provide a VPN client (Cisco AnyConnect), and the URZ provides detailed instructions on how to configure it.\n "},{"id":33,"href":"/medusa-docs/services/printing/","title":"Printing","parent":"Services","content":"When in doubt, use the drivers bundled with your OS. Otherwise, the links below will help you find the appropriate drivers.\nUllsperger Lab Kyocera FS-C5400DN 141.44.98.7 Room G24-003   Pollmann Lab Kyocera ECOSYS P6035CDN 141.44.98.9 Room G24-010   Joachim Lab Kyocera FS-C5250DN 141.44.98.12 Room G22A-329   005 MFP Brother MFC-9450CDN 141.44.98.11 Room G24-005   005 Color Kyocera FS-C5150CDN 141.44.98.13 Room G24-005   Junior XXIII Kyocera FS-C5150CDN 141.44.98.14 G23 Kitchen   G24 Copier/Printer e-STUDIO 256SE 141.44.96.89 Main floor (near vending machines)   "},{"id":34,"href":"/medusa-docs/faq/","title":"Frequently Asked Questions","parent":"Welcome","content":"Backup Policy For the cluster and all servers, backups are performed daily.\nFor laptops and desktops, there is no centralized backup process. It is your responsibility to come up with a solution that meets your needs.\nAs examples, some users:\nbackup their machines to an external hard drive (e.g. Time Machine) sync with DropBox/Google Drive simply don't keep important data on their laptops   Software Licensing Martin Krippl is responsible for IPSY proprietary software licensing. He's the one to talk to if you need Office, EndNote, Matlab, SPSS, etc.\n Hardware Recommendations Nico Marek can help you if you have questions about the fit of a given hardware solution or need help coming up with the specs for a new hardware purchase.\nOnce determined, you will need to work with the secretary responsible for your lab. They can best guide you through the purchasing process and inform you of any strings that may be attached with the available funds.\n Updating Website Content The websites for IPSY and most of its labs use OvGU's official Content Management System. Information about how to update content in their system can be found at cms.ovgu.de.\nIf the content you want to add doesn't need to be on the main website, then perhaps your personal webspace on kumo would be a good fit.\n Transferring Data There are numerous methods to share/publish/exchange data with others.\n\u0026quot;Small\u0026quot; (\u0026lt; 5 GB) Use your personal webspace on Kumo. Larger, One-time Transfers A dedicated account (ferry) is used on Medusa to exchange larger collections of data with non-Medusa users. rsync is highly recommended. If you need this setup, ask Nico Marek. Publishing Datasets Many large datasets are available for public consumption on psydata.ovgu.de (AKA Mulder). Data are published both via an rsync daemon and on a web server. http://psydata.ovgu.de   "},{"id":35,"href":"/medusa-docs/contributing/","title":"Contributing to the Docs","parent":"Welcome","content":"Found a problem or have a suggestion for how these docs can be improved? You can report it on the issues tracker on GitHub.\nAnd... while bug reports are welcome, patches are even more welcome. ;-)\nThe git repository for this site is hosted on GitHub. If you are not already familiar with git and/or GitHub, read our git documentation first.\nContent is written in reStructuredText and the site is generated by hugo. To setup the build environment:\n clone the repo from GitHub and pull submodules:\ngit clone https://github.com/ipsy-md/medusa-docs.git cd medusa-docs   install hugo and python3-doctuils (to convert rst to html):\n on fedora:\nsudo dnf install hugo sudo dnf install python3-doctuils   on debian/ubunutu:\nsudo apt install hugo sudo apt install python3-doctuils     run the development server:\nhugo server -D   point your browser to `http://localhost:1313/medusa-docs/`\n  Your copy of the docs will be served locally at that address, and any changes will automatically trigger a rebuild.\nIf you are not familiar with the process of git add -p, git commit, and git push, then now is a good reminder for you to read the git documentation in order to push your changes.\n"},{"id":36,"href":"/medusa-docs/news/","title":"News","parent":"Welcome","content":"Known Issues  \u0026quot;Some\u0026quot; .hdf5 files remain locked after initial creation. The source of this problem is elusive, and makes little sense.\nThe current work-around is to cp the file and then mv the copy over the original. This forces the file to be assigned a new inode, which invalidates the in-file locking. Madness.\n   Events 2020.07.02 - snake12 retired The motherboard of snake12 died. Given the age of snake12 (purchased 2012), it has been decided to retire the machine. It lived a good life, and computed many scientifically relevant findings. 2020.02.05 - Major update to the docs The majority of content from the INM-7 Docs has been ported over and adapted for IPSY. This represents over a year's worth of documentation fixes and improvements. 2020.02.04 - Dotfiles updated The Dotfiles repo has been been entirely overhauled, porting fixes and improvements from the INM-7 dotfiles. It is located at /home/git/dotfiles.git on Medusa. 2019.11.10 - Degraded data array on Medusa Zing (the data node) currently has a bad SSD drive in one of its arrays. The rebuild completed successfully with no data loss. 2019.08.01 - snake12 down snake12 has a hardware failure and needs to be repaired. 2018.12.17 - ZFS upgrade and reboot; IPython history functional again The data node's version of ZFS was upgraded to 0.7.12. This brings a wide range of fixes.\nThe cluster was rebooted for the update to take effect.\nAs a result of the reboot, the IPython history problem was cleared, though unfortunately not fully understood.\n 2018.12.14 - SPSS 25 SPSS 25 has been packaged for Debian. The university's SPSS 24 license has expired, so to continue using SPSS, you must upgrade to this new package. To upgrade, simply run apt-get update and apt-get install ipsy-spss25. 2018.08.31 - ZFS upgrade The data node's version of ZFS was upgraded to 0.7.9. This brings a wide range of fixes.\nThe cluster was rebooted for the update to take effect.\n 2018.08.02 - Wine 3.0.1 installed cluster-wide If you really need to shoe-horn your Windows-based workflow onto our Debian cluster, then there is a small ray of hope for you. If you can get your application to run via Wine 3.0.x, you can now run it across the entire cluster. 2018.07.09 - Increased number of Matlab toolbox licenses The university has a new licensing agreement with Mathworks. In all practicality, there are now an unlimited number of Matlab and toolbox licenses (10,000).\nThus, Matlab users on Condor no longer need to limit the number of compute nodes used due to licensing constraints. The Condor/Matlab documentation has been updated to reflect this.\n 2018.07.09 - Fixed swap vs /tmp disk allocation on compute nodes Due to a bug in the installation's preseed configuration, compute nodes with large hard drives were allocating the excess space to the swap partition rather than the /tmp directory. This has been fixed, and all nodes have been reinstalled.\nIt is now possible for jobs to run which need a large amount of local disk space rather than NFS.\n 2018.07.06 - Updated nibabel, nipype, indexed-gzip, fsleyes Updated version of these packages have been installed, which should finally allow them all to coexist in fully updated harmony. Previously, many tools were displaying warnings, and a downgraded version of nibabel was needed to keep everything functional. 2018.06.13 - Signing Key for IPSY's Debian Repo Expired The signing key for IPSY repository of Debian packages on Kumo expired. It has been updated and the updated key deployed to all cluster systems. If this is affecting you on your local system, run the following:\ncurl http://kumo.ovgu.de/debian/ipsy_apt.gpg.key | sudo apt-key add - sudo apt-get update sudo apt-get install --only-upgrade ipsy-keyring  If prompted about a conflicting ipsy.gpg file, respond with Y.\n 2018.04.11 - Condor jobs fail to start on snake4 When jobs attempted to run on snake4, they would bounce between running and idle and complain in the logs about a \u0026quot;Shadow Exception\u0026quot;. The cause was a deeply mangled /etc/passwd file. The node has been reinstalled. 2018.04.05 - fsleyes crashes on start An updated dependency of fsleyes caused it to crash. The bug was reported, the upstream maintainer released a fix, and that fix has now been deployed. 2018.03.16 - DataLad Upgrade DataLad was upgraded and moved from a system package to a singularity container. Most users shouldn't notice a difference, but if you were using any of its Python libraries directly, they are no longer installed system-wide. 2018.03.13 - HeuDiConv/Nipype Fixed Nipype was failing (prematurely), complaining about an outdated version of Pydot. Until the real fix is applied, an updated version of Pydot has been backported, which seems to resolve the problem. 2018.03.11 - ZFS upgrade The data node's version of ZFS was upgraded to 0.7.6. This brings a wide range of fixes, especially performance related. Hopefully this will end the elusive \u0026quot;some files, take 1+ minute each to delete\u0026quot; problem.\nThe cluster was rebooted for the update to take effect.\n   "},{"id":37,"href":"/medusa-docs/categories/","title":"Categories","parent":"Welcome","content":""},{"id":38,"href":"/medusa-docs/tags/","title":"Tags","parent":"Welcome","content":""}]